{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ransaka/learning/NLP/sinhala-nlp_backup/sinlib/examples/example.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ransaka/learning/NLP/sinhala-nlp_backup/sinlib/examples/example.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msinlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.sinlib.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=100.0)\"), '(Request ID: 416727ba-827b-4ae2-8174-5406501d9bee)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/ransaka/learning/NLP/sinhala-nlp_backup/sinlib/examples/example.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ransaka/learning/NLP/sinhala-nlp_backup/sinlib/examples/example.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ransaka/learning/NLP/sinhala-nlp_backup/sinlib/examples/example.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mRansaka/sinhala-450M-sample\u001b[39;49m\u001b[39m\"\u001b[39;49m, token\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhf_ZRAPIRmrowKvErzzvmAQsXHOPOhPxYgRIv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/datasets/load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2125\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2126\u001b[0m )\n\u001b[1;32m   2128\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2129\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2130\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2131\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2132\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2133\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2134\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2135\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2136\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2137\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2138\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2139\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2140\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2141\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2142\u001b[0m )\n\u001b[1;32m   2144\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2145\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/datasets/load.py:1815\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1813\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1814\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1815\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1816\u001b[0m     path,\n\u001b[1;32m   1817\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1818\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1819\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1820\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1821\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1822\u001b[0m )\n\u001b[1;32m   1823\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/datasets/load.py:1512\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1508\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1509\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1510\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1511\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1512\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1514\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1515\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1516\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/datasets/load.py:1479\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1476\u001b[0m             msg \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. If the repo is private or gated, make sure to log in with `huggingface-cli login`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1477\u001b[0m         )\n\u001b[1;32m   1478\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1480\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m [sibling\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m sibling \u001b[39min\u001b[39;00m dataset_info\u001b[39m.\u001b[39msiblings]:\n\u001b[1;32m   1481\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1482\u001b[0m         path,\n\u001b[1;32m   1483\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         dynamic_modules_path\u001b[39m=\u001b[39mdynamic_modules_path,\n\u001b[1;32m   1487\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/datasets/load.py:1453\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m hf_api \u001b[39m=\u001b[39m HfApi(config\u001b[39m.\u001b[39mHF_ENDPOINT)\n\u001b[1;32m   1452\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m     dataset_info \u001b[39m=\u001b[39m hf_api\u001b[39m.\u001b[39;49mdataset_info(\n\u001b[1;32m   1454\u001b[0m         repo_id\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1455\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1456\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m   1457\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39m100.0\u001b[39;49m,\n\u001b[1;32m   1458\u001b[0m     )\n\u001b[1;32m   1459\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1461\u001b[0m         e,\n\u001b[1;32m   1462\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         ),\n\u001b[1;32m   1467\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/hf_api.py:1760\u001b[0m, in \u001b[0;36mHfApi.dataset_info\u001b[0;34m(self, repo_id, revision, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[39mif\u001b[39;00m files_metadata:\n\u001b[1;32m   1758\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mblobs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1760\u001b[0m r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mget(path, headers\u001b[39m=\u001b[39;49mheaders, timeout\u001b[39m=\u001b[39;49mtimeout, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m   1761\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1762\u001b[0m d \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    531\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    534\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidHeader(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=100.0)\"), '(Request ID: 416727ba-827b-4ae2-8174-5406501d9bee)')"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Ransaka/sinhala-450M-sample\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_data = dataset['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.train(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ransaka/learning/NLP/sinhala-nlp/examples/example.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ransaka/learning/NLP/sinhala-nlp/examples/example.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m remove_english_characters\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.utils'"
     ]
    }
   ],
   "source": [
    "from src.utils.preprocessing import remove_english_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"this is english text, මෙය ඉංග්‍රීසි පාඨයකි, இது தமிழ் உரை\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", මෙය ඉංග්‍රීසි පාඨයකි, இது தமிழ் உரை\n"
     ]
    }
   ],
   "source": [
    "print(remove_english_characters(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "english_alphabet = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_chars = list(tokenizer.vocab_map.keys())\n",
    "unique_chars = \"\".join(unique_chars).lower()\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars = [char for char in unique_chars if char not in english_alphabet]\n",
    "unique_chars = list(set(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del unique_chars\n",
    "# with open(\"../data/sinhala_chars_with_special_chars.txt\",'w') as f:\n",
    "#     for line in unique_chars:\n",
    "#         f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sinhala_chars_with_special_chars.txt\",'r') as f:\n",
    "    unique_chars = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "input_string = \"\".join([char for char in text if char in unique_chars])\n",
    "cleaned_string = re.sub(r'\\s+', ' ', input_string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', මෙය ඉංග්රීසි පාඨයකි,'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   , මෙය ඉංග්රීසි පාඨයකි,   '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_string = tokenizer.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk><unk><unk><unk> <unk><unk> <unk><unk><unk><unk><unk><unk><unk> <unk><unk><unk><unk>, මෙය ඉංග්<unk>රීසි පාඨයකි, இது தமிழ் உரை'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import process_text_with_token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ක', 'රු', 'මෙ', ' ', 'ගො', 'ඩ', 'ක්', ' ', 'උ', 'න්', 'ට'], 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text_with_token_counts(\"කරුමෙ ගොඩක් උන්ට\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sinhala_token_percentage(text):\n",
    "#     tokenized_text, sinhala_token_count = process_text_with_token_counts(text)\n",
    "#     tokenized_text = [tok for tok in tokenized_text if tok != \" \"]\n",
    "#     return sinhala_token_count / len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.preprocessing import get_sinhala_token_percentage\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinhala_token_percentage(text):\n",
    "    if isinstance(text, str):\n",
    "        tokenized_text, sinhala_token_count = process_text_with_token_counts(text)\n",
    "        tokenized_text = [tok for tok in tokenized_text if tok != \" \"]\n",
    "        return sinhala_token_count / len(tokenized_text)\n",
    "    elif isinstance(text, list):\n",
    "        pool = multiprocessing.Pool()\n",
    "        results = pool.map(process_text_with_token_counts, text)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        encodings = [tok[0] for tok in results if tok[0] != \" \"]\n",
    "        encodings = [[char for char in enc if char!=\" \"] for enc in encodings]\n",
    "        sinhala_lengths = [tok[1] for tok in results]\n",
    "        return [(l/len(enc)) for enc,l in zip(encodings,sinhala_lengths )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinhala_perct = get_sinhala_token_percentage(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
